{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MVTorch](https://github.com/ajhamdi/mvtorch) 3D Calssification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- install `mvtorch` from [here](https://github.com/ajhamdi/mvtorch/blob/main/INSTALL.md) and activate the environment in the notebook.\n",
    "\n",
    "- download common 3D datasets ([ModelNet40](https://drive.google.com/uc?export=download&id=157W0qYR2yQAc5qKmXlZuHms66wmUM8Hi), [ScanObjectNN](https://drive.google.com/uc?export=download&id=15xhYA8SC5EdLKZA_xV0FXyRy8f-qGMs5)) and unzip inside `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && cd .. && cd data/ \n",
    "# # download ModelNet40 from https://mega.nz/file/mm5FhJ7I#jGECWn-QSCLH9LLoxhZzSWnf9LCtCavV12toj9SJKPM \n",
    "# # download ScanObjectNN from https://mega.nz/file/ampg2QyT#Exo22r-8jzgCa2MOqoqipd39HVqYKG5iykJ5bovjsuI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depenenancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from mvtorch.data import ScanObjectNN, CustomDataLoader\n",
    "from mvtorch.networks import MVNetwork\n",
    "from mvtorch.view_selector import MVTN\n",
    "from mvtorch.mvrenderer import MVRenderer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='../data/ScanObjectNN' # specifiy where did you put the data rel\n",
    "nb_views = 1 # Number of views generated by view selector\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train = ScanObjectNN(data_dir=data_dir, split='train')\n",
    "dset_test = ScanObjectNN(data_dir=data_dir, split='test')\n",
    "train_loader = CustomDataLoader(dset_train, batch_size=5, shuffle=True, drop_last=False)\n",
    "test_loader = CustomDataLoader(dset_test, batch_size=5, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define main components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hamdiaj/.cache/torch/hub/pytorch_vision_v0.8.2\n"
     ]
    }
   ],
   "source": [
    "# Create backbone multi-view network (ResNet18)\n",
    "mvnetwork = MVNetwork(num_classes=len(dset_train.classes), num_parts=None, mode='cls', net_name='resnet18').cuda()\n",
    "\n",
    "# Create backbone optimizer\n",
    "optimizer = torch.optim.AdamW(mvnetwork.parameters(), lr=0.00001, weight_decay=0.03)\n",
    "\n",
    "# Create view selector\n",
    "mvtn = MVTN(nb_views=nb_views).cuda()\n",
    "\n",
    "# Create optimizer for view selector (In case views are not fixed, otherwise set to None)\n",
    "# mvtn_optimizer = torch.optim.AdamW(mvtn.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "mvtn_optimizer = None\n",
    "\n",
    "# Create multi-view renderer\n",
    "mvrenderer = MVRenderer(nb_views=nb_views, return_mapping=False)\n",
    "\n",
    "# Create loss function for training\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "\n",
      "\n",
      "Training...\n",
      "\tBatch 116/464: Current Average Training Loss = 2.69195\n",
      "\tBatch 232/464: Current Average Training Loss = 2.52120\n",
      "\tBatch 348/464: Current Average Training Loss = 2.42160\n",
      "\tBatch 464/464: Current Average Training Loss = 2.33012\n",
      "\n",
      "Average Training Loss = 2.33012. Average Training Accuracy = 25.61.\n",
      "\n",
      "\n",
      "Testing...\n",
      "\tBatch 29/117: Current Average Test Loss = 2.07354\n",
      "\tBatch 58/117: Current Average Test Loss = 1.85165\n",
      "\tBatch 87/117: Current Average Test Loss = 1.87505\n",
      "\tBatch 116/117: Current Average Test Loss = 1.89656\n",
      "\n",
      "Total Average Test Loss = 1.90131.  Average Test Accuracy = 44.77.\n",
      "\n",
      "Epoch 2/100\n",
      "\n",
      "\n",
      "Training...\n",
      "\tBatch 116/464: Current Average Training Loss = 2.01555\n",
      "\tBatch 232/464: Current Average Training Loss = 1.93305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m mvrenderer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (targets, meshes, points) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     10\u001b[0m     azim, elev, dist \u001b[38;5;241m=\u001b[39m mvtn(points, c_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(targets))\n\u001b[1;32m     11\u001b[0m     rendered_images, _ \u001b[38;5;241m=\u001b[39m mvrenderer(meshes, points, azim\u001b[38;5;241m=\u001b[39mazim, elev\u001b[38;5;241m=\u001b[39melev, dist\u001b[38;5;241m=\u001b[39mdist)\n",
      "File \u001b[0;32m~/anaconda3/envs/mvtorchenv1/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/mvtorchenv1/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/mvtorchenv1/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/mvtorchenv1/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/mvtorchenv1/lib/python3.9/site-packages/mvtorch/data.py:649\u001b[0m, in \u001b[0;36mScanObjectNN.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    647\u001b[0m obj_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects_paths[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit][idx]\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# obj_path,label\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_pc_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# sample the required number of points randomly\u001b[39;00m\n\u001b[1;32m    651\u001b[0m points \u001b[38;5;241m=\u001b[39m points[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(points\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_points),:]\n",
      "File \u001b[0;32m~/anaconda3/envs/mvtorchenv1/lib/python3.9/site-packages/mvtorch/data.py:669\u001b[0m, in \u001b[0;36mScanObjectNN.load_pc_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_pc_file\u001b[39m(\u001b[38;5;28mself\u001b[39m,filename):\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;66;03m#load bin file\u001b[39;00m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;66;03m# pc=np.fromfile(filename, dtype=np.float32)\u001b[39;00m\n\u001b[0;32m--> 669\u001b[0m     pc \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;66;03m#first entry is the number of points\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;66;03m#then x, y, z, nx, ny, nz, r, g, b, label, nyu_label\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuncg):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    correct = 0.0\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    print(\"\\n\\nTraining...\")\n",
    "    mvnetwork.train()\n",
    "    mvtn.train()\n",
    "    mvrenderer.train()\n",
    "    running_loss = 0\n",
    "    for i, (targets, meshes, points) in enumerate(train_loader):\n",
    "        azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "        rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "        outputs = mvnetwork(rendered_images)[0]\n",
    "\n",
    "        loss = criterion(outputs, targets.cuda())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if mvtn_optimizer is not None:\n",
    "            mvtn_optimizer.step()\n",
    "            mvtn_optimizer.zero_grad()\n",
    "        \n",
    "        if (i + 1) % int(len(train_loader) * 0.25) == 0:\n",
    "            print(f\"\\tBatch {i + 1}/{len(train_loader)}: Current Average Training Loss = {(running_loss / (i + 1)):.5f}\")\n",
    "    print(f\"\\nAverage Training Loss = {(running_loss / len(train_loader)):.5f}. Average Training Accuracy = {(100.0*correct / len(dset_train)):.2f}.\")\n",
    "\n",
    "    print(\"\\n\\nTesting...\")\n",
    "    mvnetwork.eval()\n",
    "    mvtn.eval()\n",
    "    mvrenderer.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0.0\n",
    "    for i, (targets, meshes, points) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "            rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "            outputs = mvnetwork(rendered_images)[0]\n",
    "\n",
    "            loss = criterion(outputs, targets.cuda())\n",
    "            running_loss += loss.item()\n",
    "            correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "\n",
    "            if (i + 1) % int(len(test_loader) * 0.25) == 0:\n",
    "                print(f\"\\tBatch {i + 1}/{len(test_loader)}: Current Average Test Loss = {(running_loss / (i + 1)):.5f}\")\n",
    "    print(f\"\\nTotal Average Test Loss = {(running_loss / len(test_loader)):.5f}.  Average Test Accuracy = {(100.0*correct / len(dset_test)):.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] visualize results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mvtorchenv1]",
   "language": "python",
   "name": "conda-env-mvtorchenv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
